data =  data.all)+
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('LDL')
p7<-ggplot(aes(x=hdl),
data =  data.all ) +
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('HDL')
p8<-ggplot(aes(x=tch),data=data.all)+
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('TCH')
p9<-ggplot(aes(x=ltg),
data =  data.all)+
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('LTG')
p10<-ggplot(aes(x=glu),
data =  data.all)+
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('Glucose')
p11<-ggplot(aes(x=y),
data =  data.all ) +
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('Quantitative Progression of Disease')
grid.arrange(p1,p2,p3,p3,p4,p5,p6,p7,p8,p9,p10,p11,ncol=3)
#There is no missing data, all variables are numeric, there are 442 data points and 11 variables
p11<-ggplot(aes(x=y),           data =  data.all ) +  geom_histogram(color =I('black'),fill = I('#099009'))+  ggtitle('Disease Progression')
p11<-ggplot(aes(x=y),
data =  data.all ) +
geom_histogram(color =I('black'),fill = I('#099009'))+
ggtitle('Disease Progression')
grid.arrange(p1,p2,p3,p3,p4,p5,p6,p7,p8,p9,p10,p11,ncol=3)
dim(data.all)
grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,ncol=3)
coef(regfit.full ,6)
grid =10^seq(10,-2, length =100)
ridge.mod =glmnet(x.train,y.train,alpha =0, lambda =grid)
plot(ridge.mod, xvar="lambda", label=T)
set.seed(1306)
cv.out <- cv.glmnet(x.train,y.train,alpha =0)
bestlam <- cv.out$lambda.1se
bestlam
plot(cv.out)
grid =10^seq(10,-2, length =100)
lasso.mod =glmnet(x.train,y.train,alpha =1, lambda =grid)
plot(lasso.mod, xvar="lambda", label=T)
set.seed(1306)
cv.out <- cv.glmnet(x.train,y.train,alpha =1)
bestlam <- cv.out$lambda.1se
bestlam
plot(cv.out)
log(bestlam)
plot(lasso.mod, xvar="lambda", label=T)
grid =10^seq(10,-2, length =100)
ridge.mod =glmnet(x.train,y.train,alpha =0, lambda =grid)
plot(ridge.mod, xvar="lambda", label=T)
set.seed(1306)
cv.out <- cv.glmnet(x.train,y.train,alpha =0)
bestlam <- cv.out$lambda.1se
bestlam
log(bestlam)
grid =10^seq(10,-2, length =100)
ridge.mod =glmnet(x.train,y.train,alpha =0, lambda =grid)
plot(ridge.mod, xvar="lambda", label=T)
set.seed(1306)
cv.out <- cv.glmnet(x.train,y.train,alpha =0)
plot(cv.out)
ridge.coef=predict(cv.out ,type ="coefficients",s=bestlam )[1:10 ,]
ridge.coef
ridge.coef=predict(cv.out ,type ="coefficients",s=bestlam )[1:11,]
ridge.coef
lasso.coef=predict(cv.out ,type ="coefficients",s=bestlam )[1:11 ,]
lasso.coef
grid =10^seq(10,-2, length =100)
lasso.mod =glmnet(x.train,y.train,alpha =1, lambda =grid)
plot(lasso.mod, xvar="lambda", label=T)
set.seed(1306)
cv.out <- cv.glmnet(x.train,y.train,alpha =1)
bestlam <- cv.out$lambda.1se
bestlam
# [1] 4.791278
#Mean Prediction Error:
lasso.pred=predict(lasso.mod ,s=bestlam ,newx=x.test)
mean((lasso.pred -y.test)^2)
# [1] 2920.08
#SE of MSE
sd((lasso.pred -y.test)^2)/sqrt(length((lasso.pred -y.test)^2))
# [1] 346.228
##Coefficients:
lasso.coef=predict(cv.out ,type ="coefficients",s=bestlam )[1:11 ,]
lasso.coef
regfit.pred <- predict.regsubsets(regfit.full,data.test,id=6)
mean((regfit.pred -data.test$y)^2)
sd((regfit.pred -data.test$y)^2)/sqrt(length((regfit.pred -data.test$y)^2))
save.image("~/Documents/Work_Computer/Grad_School/PREDICT_422/Module4/IndividualProject1/Project1.RData")
oib_isp <- summaryBy(inbox_rate ~ COMMON_NAME,data=oib,FUN= mean,na.rm=TRUE)
library(doBy)
oib_isp <- summaryBy(inbox_rate ~ COMMON_NAME,data=oib,FUN= mean,na.rm=TRUE)
setwd("/Users/asheets/Documents/Work_Computer/Grad_School/PREDICT_422/PREDICT422_GroupProject")
set.seed(1)
#Install Packages
install.packages("doBy")
install.packages("psych")
install.packages("lars")
install.packages("GGally")
install.packages("ggplot2")
install.packages("gridExtra")
install.packages("corrgram")
install.packages("corrplot")
install.packages("leaps")
install.packages("glmnet")
install.packages("MASS")
install.packages("gbm")
install.packages("tree")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("gam")
install.packages("class")
install.packages("e1071")
library(doBy)
library(psych)
library(lars)
library(GGally)
library(ggplot2)
library (gridExtra)
library(corrgram)
library(corrplot)
library(leaps)
library(glmnet)
library(MASS)
library(gbm)
library(tree)
library(rpart)
library(rpart.plot)
library(gam)
library(class)
library(e1071)
library(randomForest)
list.of.packages <- c(,("doBy")
,("psych")
,("lars")
,("GGally")
,("ggplot2")
,("gridExtra")
,("corrgram")
,("corrplot")
,("leaps")
,("glmnet")
,("MASS")
,("gbm")
,("tree")
,("rpart")
,("rpart.plot")
,("gam")
,("class")
,("e1071"))
list.of.packages <- c(("doBy")
,("psych")
,("lars")
,("GGally")
,("ggplot2")
,("gridExtra")
,("corrgram")
,("corrplot")
,("leaps")
,("glmnet")
,("MASS")
,("gbm")
,("tree")
,("rpart")
,("rpart.plot")
,("gam")
,("class")
,("e1071"))
list.of.packages
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(doBy)
library(psych)
library(lars)
library(GGally)
library(ggplot2)
library (gridExtra)
library(corrgram)
library(corrplot)
library(leaps)
library(glmnet)
library(MASS)
library(gbm)
library(tree)
library(rpart)
library(rpart.plot)
library(gam)
library(class)
library(e1071)
library(randomForest)
# Load the diabetes data
data <- read.csv(file="charity.csv",stringsAsFactors=FALSE,header=TRUE,quote="",comment.char="")
dim(data)
summary(data) # donr and damt each have 2007 NA values -- these are the test set
str(data) # all int except agif is num and part is a factor with 3 levels
head(data)
class(data) # data.frame
nrow(data) # 8009 rows
ncol(data) # 24 variables
names(data)
charity.t <- data
#These variables are all skewed right
charity.t$avhv <- log(charity.t$avhv)
charity.t$inca <- log(charity.t$inca)
charity.t$incm <- log(charity.t$incm)
charity.t$agif <- log(charity.t$agif)
charity.t$rgif <- log(charity.t$rgif)
charity.t$lgif <- log(charity.t$lgif)
charity.t$tgif <- log(charity.t$tgif)
data.train <- charity.t[charity.t$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
data.valid <- charity.t[charity.t$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999
data.test <- charity.t[charity.t$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]
x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1
x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1
x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)
plots3 <- lapply(colnames(data.train.std.c)[1:21], plot_vars, data = data.train.std.c[1:21])
n <- length(plots3)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(plots3))
#Visualize the variables
plot_vars = function (data, column)
ggplot(data = data, aes_string(x = column)) +
geom_histogram(color =I('black'),fill = I('#099009'))+
xlab(column)
plots3 <- lapply(colnames(data.train.std.c)[1:21], plot_vars, data = data.train.std.c[1:21])
list.of.packages <- c("doBy"
,"psych"
,"lars"
,"GGally"
,"ggplot2"
,"gridExtra"
,"corrgram"
,"corrplot"
,"leaps"
,"glmnet"
,"MASS"
,"gbm"
,"tree"
,"rpart"
,"rpart.plot"
,"gam"
,"class"
,"e1071"
,"ggplot2")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(doBy)
library(psych)
library(lars)
library(GGally)
library(ggplot2)
library (gridExtra)
library(corrgram)
library(corrplot)
library(leaps)
library(glmnet)
library(MASS)
library(gbm)
library(tree)
library(rpart)
library(rpart.plot)
library(gam)
library(class)
library(e1071)
library(randomForest)
plots3 <- lapply(colnames(data.train.std.c)[1:21], plot_vars, data = data.train.std.c[1:21])
n <- length(plots3)
?ggplot
??ggplot
library(ggplot2)
install.package("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library("ggplot2", lib.loc="~/Library/R/3.2/library")
plots3 <- lapply(colnames(data.train.std.c)[1:21], plot_vars, data = data.train.std.c[1:21])
n <- length(plots3)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(plots3))
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
set.seed(1)
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid1 <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid1, max(profit.log1)) # report number of mailings and maximum profit
table(chat.valid.log1, c.valid) # classification table
cutoff.log1 <- sort(post.valid.log1, decreasing=T)[n.mail.valid1+1] # set cutoff based on n.mail.valid
chat.valid.log1 <- ifelse(post.valid.log1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.log1, c.valid) # classification table
344+986
14.5*986-2*1330
set.seed(1)
model.gam1=gam(donr~reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + s(agif ,df =5),
family = binomial , data = data.train.std.c)
post.valid.gam1 <- predict(model.gam1, data.valid.std.c, type="response") # n.valid post probs
profit.gam1 <- cumsum(14.5*c.valid[order(post.valid.gam1, decreasing=T)]-2)
plot(profit.gam1) # see how profits change as more mailings are made
n.mail.valid1 <- which.max(profit.gam1) # number of mailings that maximizes profits
c(n.mail.valid1, max(profit.gam1)) # report number of mailings and maximum profit
cutoff.gam1 <- sort(post.valid.gam1, decreasing=T)[n.mail.valid1+1] # set cutoff based on n.mail.valid
chat.valid.gam1 <- ifelse(post.valid.gam1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.gam1, c.valid) # classification table
443+979
14.5*979-2*1442
model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c)
set.seed(1)
model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c) # include additional terms on the fly using I()
post.valid.lda1 <- predict(model.lda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs
profit.lda1 <- cumsum(14.5*c.valid[order(post.valid.lda1, decreasing=T)]-2)
plot(profit.lda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.lda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.lda1)) # report number of mailings and maximum profit
cutoff.lda1 <- sort(post.valid.lda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.lda1 <- ifelse(post.valid.lda1>cutoff.lda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.lda1, c.valid) # classification table
397 + 991
14.5*991-2*1391
model.qda1 =qda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,data= data.train.std.c)
post.valid.qda1 <- predict(model.qda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs
profit.qda1 <- cumsum(14.5*c.valid[order(post.valid.qda1, decreasing=T)]-2)
plot(profit.qda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.qda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.qda1)) # report number of mailings and maximum profit
cutoff.qda1 <- sort(post.valid.qda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.qda1 <- ifelse(post.valid.qda1>cutoff.qda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.qda1, c.valid) # classification table
429+967
14.5*967-2*1396
set.seed(1)
model.knn1=knn(x.train.std,x.valid.std,c.train,k=1)
mean(c.valid != model.knn1)
table(model.knn1 ,c.valid)
profit.knn1 <- cumsum(14.5*c.valid[order(model.knn1, decreasing=T)]-2)
plot(profit.knn1) # see how profits change as more mailings are made
mean((as.numeric(as.character(model.knn1)) - c.valid)^2)
281+835
14.5*835-2*1116
charity.t <- data
charity.t$avhv <- log(charity.t$avhv)
charity.t$inca <- log(charity.t$inca)
charity.t$incm <- log(charity.t$incm)
charity.t$agif <- log(charity.t$agif)
charity.t$rgif <- log(charity.t$rgif)
charity.t$lgif <- log(charity.t$lgif)
significant.correlations <- data.frame(
var1 = character(),
var2 = character(),
corr = numeric())
#
for (i in 1:nrow(correlations)){
for (j in 1:ncol(correlations)){
tmp <- data.frame(
var1 = as.character(colnames(correlations)[j]),
var2 = as.character(rownames(correlations)[i]),
corr = correlations[i,j])
#
if (!is.na(correlations[i,j])) {
if (correlations[i,j] > .5 & as.character(tmp$var1) != as.character(tmp$var2)
| correlations[i,j] < -.5 & as.character(tmp$var1) != as.character(tmp$var2) ) {
significant.correlations <- rbind(significant.correlations,tmp) }
}
}
}
significant.correlations <- significant.correlations[order(abs(significant.correlations$corr),decreasing=TRUE),]
significant.correlations <- significant.correlations[which(!duplicated(significant.correlations$corr)),]
significant.correlations
correlations <- data.frame(cor(charity.t[sapply(charity.t, is.numeric)],use="complete.obs"))
significant.correlations <- data.frame(
var1 = character(),
var2 = character(),
corr = numeric())
#
for (i in 1:nrow(correlations)){
for (j in 1:ncol(correlations)){
tmp <- data.frame(
var1 = as.character(colnames(correlations)[j]),
var2 = as.character(rownames(correlations)[i]),
corr = correlations[i,j])
#
if (!is.na(correlations[i,j])) {
if (correlations[i,j] > .5 & as.character(tmp$var1) != as.character(tmp$var2)
| correlations[i,j] < -.5 & as.character(tmp$var1) != as.character(tmp$var2) ) {
significant.correlations <- rbind(significant.correlations,tmp) }
}
}
}
significant.correlations <- significant.correlations[order(abs(significant.correlations$corr),decreasing=TRUE),]
significant.correlations <- significant.correlations[which(!duplicated(significant.correlations$corr)),]
significant.correlations
data.train <- charity.t[charity.t$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
data.valid <- charity.t[charity.t$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999
data.test <- charity.t[charity.t$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]
x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1
x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1
x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)
set.seed(1)
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid1 <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid1, max(profit.log1)) # report number of mailings and maximum profit
charity.t <- data
data.train <- charity.t[charity.t$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995
data.valid <- charity.t[charity.t$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999
data.test <- charity.t[charity.t$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]
x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1
x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1
x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)
set.seed(1)
model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat +
avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif,
data.train.std.c, family=binomial("logit"))
post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs
profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid1 <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid1, max(profit.log1)) # report number of mailings and maximum profit
charity.t <- data
#These variables are all skewed right
charity.t$avhv <- log(charity.t$avhv)
charity.t$inca <- log(charity.t$inca)
charity.t$incm <- log(charity.t$incm)
charity.t$agif <- log(charity.t$agif)
charity.t$rgif <- log(charity.t$rgif)
charity.t$lgif <- log(charity.t$lgif)
charity.t <- data
charity.t$avhv <- log(charity.t$avhv)
charity.t$inca <- log(charity.t$inca)
charity.t$incm <- log(charity.t$incm)
charity.t <- data
